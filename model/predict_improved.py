# model/predict_improved.py - æ”¹è¿›ç‰ˆé¢„æµ‹è„šæœ¬
import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import torch
import pandas as pd
from model.model import LSTMModel
from preprocess import load_and_preprocess, create_sequences, load_scaler, inverse_transform_close
from technical_indicators import add_technical_indicators
from config_improved import *

def predict_next_candle_improved(df: pd.DataFrame):
    # åŠ è½½å·²ä¿å­˜çš„scaler
    loaded_scaler = load_scaler()
    if loaded_scaler is None:
        print("âš ï¸ No scaler found. è¯·å…ˆé‡æ–°è®­ç»ƒæ¨¡å‹ (python -m model.train_improved)")
        return None
    
    # æ£€æŸ¥scalerç‰¹å¾åä¸å½“å‰ç‰¹å¾åæ˜¯å¦ä¸€è‡´
    scaler_features = getattr(loaded_scaler, 'feature_names_in_', None)
    if scaler_features is not None:
        from config_improved import FEATURE_COLUMNS
        if list(scaler_features) != list(FEATURE_COLUMNS):
            print("âŒ æ£€æµ‹åˆ° scaler.pkl ç‰¹å¾ä¸å½“å‰ FEATURE_COLUMNS ä¸ä¸€è‡´ï¼")
            print(f"scalerç‰¹å¾: {list(scaler_features)}")
            print(f"å½“å‰ç‰¹å¾: {list(FEATURE_COLUMNS)}")
            print("è¯·åˆ é™¤ model/scaler.pkl å¹¶é‡æ–°è®­ç»ƒæ¨¡å‹: python -m model.train_improved")
            return None
    
    # æ·»åŠ æŠ€æœ¯æŒ‡æ ‡
    df_with_indicators = add_technical_indicators(df)
    
    # ä½¿ç”¨å·²ä¿å­˜çš„scalerè¿›è¡Œæ ‡å‡†åŒ–
    df_processed = df_with_indicators.copy()
    df_processed[FEATURE_COLUMNS] = loaded_scaler.transform(df_with_indicators[FEATURE_COLUMNS])

    X, y = create_sequences(df_processed, window_size=WINDOW_SIZE)
    
    if len(X) == 0:
        print("âš ï¸ Not enough data for prediction. Need at least {} data points.".format(WINDOW_SIZE + 1))
        return None

    X_latest = X[-1]
    X_tensor = torch.tensor(X_latest, dtype=torch.float32).unsqueeze(0)

    model = LSTMModel(input_size=X_tensor.shape[2], hidden_size=16, num_layers=1)
    model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device('cpu')))
    model.eval()

    with torch.no_grad():
        pred_normalized = model(X_tensor).item()

    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ç›¸å¯¹å˜åŒ–ç›®æ ‡
    try:
        from config_improved import USE_RELATIVE_CHANGE, MAX_CHANGE_RATIO
    except ImportError:
        USE_RELATIVE_CHANGE = False
        MAX_CHANGE_RATIO = 0.05
    
    if USE_RELATIVE_CHANGE:
        # ä»å½’ä¸€åŒ–çš„ç›¸å¯¹å˜åŒ–è½¬æ¢ä¸ºå®é™…å˜åŒ–å¹…åº¦
        pred_change_ratio = (pred_normalized * 2 * MAX_CHANGE_RATIO) - MAX_CHANGE_RATIO
        
        # è®¡ç®—é¢„æµ‹çš„æ”¶ç›˜ä»·
        last_close = df.iloc[-1]['close']
        pred_close = last_close * (1 + pred_change_ratio)
        
        print(f"ğŸ” é¢„æµ‹å˜åŒ–å¹…åº¦: {pred_change_ratio*100:.2f}%")
    else:
        # ä½¿ç”¨ç»å¯¹ä»·æ ¼é¢„æµ‹
        pred_close = inverse_transform_close(pred_normalized)
        last_close = df.iloc[-1]['close']
        pred_change_ratio = (pred_close - last_close) / last_close
        print(f"ğŸ” åŸå§‹é¢„æµ‹å˜åŒ–å¹…åº¦: {pred_change_ratio*100:.2f}%")

    direction = "æ¶¨" if pred_close > last_close else "è·Œ"

    last_close_time = pd.to_datetime(df.iloc[-1]["timestamp"])
    pred_time = last_close_time + pd.Timedelta(hours=1)

    return {
        "é¢„æµ‹æ”¶ç›˜ä»·": pred_close,
        "ä¸Šæ¬¡æ”¶ç›˜ä»·": last_close,
        "é¢„æµ‹æ¶¨è·Œ": direction,
        "é¢„æµ‹æ—¶é—´": pred_time.strftime("%Y-%m-%d %H:%M:%S"),
        "æ¶¨è·Œå¹…åº¦": f"{((pred_close - last_close) / last_close * 100):.2f}%"
    }

if __name__ == "__main__":
    df = pd.read_csv(DATA_PATH)
    # é‡å‘½ååˆ—ä»¥åŒ¹é…é¢„å¤„ç†å‡½æ•°
    df = df.rename(columns={
        'closeTime': 'timestamp',
        'open': 'open',
        'high': 'high',
        'low': 'low',
        'close': 'close',
        'volume': 'volume'
    })
    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
    df = df.sort_values(by='timestamp').reset_index(drop=True)
    
    # æ‰“å°æœ€åä¸€æ ¹Kçº¿
    print("ã€æœ€åä¸€æ ¹Kçº¿ã€‘")
    print(df.iloc[-1][['timestamp', 'open', 'high', 'low', 'close', 'volume']])

    # é¢„æµ‹ä¸‹ä¸€æ ¹Kçº¿
    result = predict_next_candle_improved(df)
    if result:
        print("\nã€é¢„æµ‹çš„ä¸‹ä¸€æ ¹Kçº¿ã€‘")
        print(result)
        # å¦‚æœæ•°æ®é›†é‡Œæœ‰çœŸå®çš„ä¸‹ä¸€æ ¹Kçº¿ï¼Œä¹Ÿæ‰“å°å‡ºæ¥
        next_time = pd.to_datetime(result["é¢„æµ‹æ—¶é—´"])
        real_next = df[df['timestamp'] == next_time]
        if not real_next.empty:
            print("\nã€çœŸå®çš„ä¸‹ä¸€æ ¹Kçº¿ã€‘")
            print(real_next.iloc[0][['timestamp', 'open', 'high', 'low', 'close', 'volume']])
        else:
            print("\nã€çœŸå®çš„ä¸‹ä¸€æ ¹Kçº¿ã€‘")
            print("æ•°æ®é›†ä¸­æ²¡æœ‰ä¸‹ä¸€æ ¹Kçº¿ï¼ˆå¯èƒ½æ˜¯æœ€æ–°ä¸€æ ¹ï¼‰")
    else:
        print("é¢„æµ‹å¤±è´¥ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹") 