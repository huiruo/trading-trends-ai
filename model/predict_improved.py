# model/predict_improved.py - æ”¹è¿›ç‰ˆé¢„æµ‹è„šæœ¬
import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import torch
import pandas as pd
from model.model import LSTMModel
from preprocess import load_and_preprocess, create_sequences, load_scaler, inverse_transform_close
from technical_indicators import add_technical_indicators
from config_improved import *

def predict_next_candle_improved(df: pd.DataFrame):
    # åŠ è½½å·²ä¿å­˜çš„scaler
    loaded_scaler = load_scaler()
    if loaded_scaler is None:
        print("âš ï¸ No scaler found. è¯·å…ˆé‡æ–°è®­ç»ƒæ¨¡å‹ (python -m model.train_improved)")
        return None
    
    # æ£€æŸ¥scalerç‰¹å¾åä¸å½“å‰ç‰¹å¾åæ˜¯å¦ä¸€è‡´
    scaler_features = getattr(loaded_scaler, 'feature_names_in_', None)
    if scaler_features is not None:
        from config_improved import FEATURE_COLUMNS
        if list(scaler_features) != list(FEATURE_COLUMNS):
            print("âŒ æ£€æµ‹åˆ° scaler.pkl ç‰¹å¾ä¸å½“å‰ FEATURE_COLUMNS ä¸ä¸€è‡´ï¼")
            print(f"scalerç‰¹å¾: {list(scaler_features)}")
            print(f"å½“å‰ç‰¹å¾: {list(FEATURE_COLUMNS)}")
            print("è¯·åˆ é™¤ model/scaler.pkl å¹¶é‡æ–°è®­ç»ƒæ¨¡å‹: python -m model.train_improved")
            return None
    
    # æ·»åŠ æŠ€æœ¯æŒ‡æ ‡
    df_with_indicators = add_technical_indicators(df)
    
    # ä½¿ç”¨å·²ä¿å­˜çš„scalerè¿›è¡Œæ ‡å‡†åŒ–ï¼ˆå¯¹æ‰€æœ‰ç‰¹å¾ï¼‰
    df_processed = df_with_indicators.copy()
    df_processed[FEATURE_COLUMNS] = loaded_scaler.transform(df_with_indicators[FEATURE_COLUMNS])

    X, y = create_sequences(df_processed, window_size=WINDOW_SIZE)
    
    if len(X) == 0:
        print("âš ï¸ Not enough data for prediction. Need at least {} data points.".format(WINDOW_SIZE + 1))
        return None

    X_latest = X[-1]
    X_tensor = torch.tensor(X_latest, dtype=torch.float32).unsqueeze(0)

    model = LSTMModel(input_size=X_tensor.shape[2], hidden_size=32, num_layers=2, num_classes=3)
    model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device('cpu')))
    model.eval()

    with torch.no_grad():
        pred_probs = model(X_tensor)  # å¾—åˆ°åˆ†ç±»æ¦‚ç‡
        pred_class = torch.argmax(pred_probs, dim=1).item()  # å¾—åˆ°é¢„æµ‹ç±»åˆ«

    # æ ¹æ®åˆ†ç±»ç»“æœè®¡ç®—é¢„æµ‹ä»·æ ¼
    last_close = df.iloc[-1]['close']
    
    # åˆ†ç±»ç»“æœï¼š0=è·Œï¼Œ1=å¹³ï¼Œ2=æ¶¨
    if pred_class == 0:  # è·Œ
        pred_close = last_close * 0.999  # å¾®è·Œ0.1%
        direction = "è·Œ"
    elif pred_class == 2:  # æ¶¨
        pred_close = last_close * 1.001  # å¾®æ¶¨0.1%
        direction = "æ¶¨"
    else:  # å¹³
        pred_close = last_close  # ä¸å˜
        direction = "å¹³"
    
    pred_change_ratio = (pred_close - last_close) / last_close
    print(f"ğŸ” é¢„æµ‹æ–¹å‘: {direction}, å˜åŒ–å¹…åº¦: {pred_change_ratio*100:.3f}%")

    last_close_time = pd.to_datetime(df.iloc[-1]["timestamp"])
    pred_time = last_close_time + pd.Timedelta(hours=1)

    # åˆ†æé¢„æµ‹åŸå› 
    analysis = analyze_prediction_reason(df_with_indicators, pred_change_ratio, direction)

    return {
        "é¢„æµ‹æ”¶ç›˜ä»·": pred_close,
        "ä¸Šæ¬¡æ”¶ç›˜ä»·": last_close,
        "é¢„æµ‹æ¶¨è·Œ": direction,
        "é¢„æµ‹æ—¶é—´": pred_time.strftime("%Y-%m-%d %H:%M:%S"),
        "æ¶¨è·Œå¹…åº¦": f"{((pred_close - last_close) / last_close * 100):.2f}%",
        "åˆ†æåŸå› ": analysis
    }

def analyze_prediction_reason(df: pd.DataFrame, change_ratio: float, direction: str):
    """åˆ†æé¢„æµ‹ç»“æœçš„åŸå› """
    
    # è·å–æœ€åå‡ æ ¹Kçº¿çš„æ•°æ®
    last_5 = df.tail(5)
    
    # åˆ†ææŠ€æœ¯æŒ‡æ ‡
    last_row = df.iloc[-1]
    
    analysis = f"ğŸ¤– AIåˆ†æé¢„æµ‹åŸå› ï¼š\n"
    
    # 1. ä»·æ ¼è¶‹åŠ¿åˆ†æ
    price_trend = analyze_price_trend(last_5)
    analysis += f"ğŸ“ˆ ä»·æ ¼è¶‹åŠ¿ï¼š{price_trend}\n"
    
    # 2. RSIåˆ†æ
    rsi_analysis = analyze_rsi(last_row['rsi_14'])
    analysis += f"ğŸ“Š RSIæŒ‡æ ‡ï¼š{rsi_analysis}\n"
    
    # 3. å¸ƒæ—å¸¦åˆ†æ
    bb_analysis = analyze_bollinger_bands(last_row['bb_position'])
    analysis += f"ğŸ“‰ å¸ƒæ—å¸¦ä½ç½®ï¼š{bb_analysis}\n"
    
    # 4. MACDåˆ†æ
    if 'macd_histogram' in last_row:
        macd_analysis = analyze_macd(last_row['macd_histogram'])
        analysis += f"ğŸ“Š MACDæŒ‡æ ‡ï¼š{macd_analysis}\n"
    
    # 5. KDJåˆ†æ
    if 'kdj_k' in last_row and 'kdj_d' in last_row:
        kdj_analysis = analyze_kdj(last_row['kdj_k'], last_row['kdj_d'], last_row['kdj_j'])
        analysis += f"ğŸ“Š KDJæŒ‡æ ‡ï¼š{kdj_analysis}\n"
    
    # 6. ç§»åŠ¨å¹³å‡çº¿åˆ†æ
    if 'ma5_ratio' in last_row and 'ma10_ratio' in last_row:
        ma_analysis = analyze_moving_averages(last_row['ma5_ratio'], last_row['ma10_ratio'], last_row['ma20_ratio'])
        analysis += f"ğŸ“ˆ ç§»åŠ¨å¹³å‡çº¿ï¼š{ma_analysis}\n"
    
    # 7. æˆäº¤é‡åˆ†æ
    volume_analysis = analyze_volume(last_5)
    analysis += f"ğŸ“Š æˆäº¤é‡è¶‹åŠ¿ï¼š{volume_analysis}\n"
    
    # 8. åŠ¨é‡åˆ†æ
    if 'momentum_5' in last_row:
        momentum_analysis = analyze_momentum(last_row['momentum_5'], last_row['momentum_10'])
        analysis += f"ğŸ“Š åŠ¨é‡æŒ‡æ ‡ï¼š{momentum_analysis}\n"
    
    # 9. ç»¼åˆåˆ¤æ–­
    overall_analysis = get_overall_analysis(change_ratio, direction, last_row)
    analysis += f"ğŸ¯ ç»¼åˆåˆ¤æ–­ï¼š{overall_analysis}\n"
    
    return analysis

def analyze_price_trend(last_5: pd.DataFrame):
    """åˆ†æä»·æ ¼è¶‹åŠ¿"""
    closes = last_5['close'].values
    if len(closes) < 3:
        return "æ•°æ®ä¸è¶³"
    
    # è®¡ç®—æœ€è¿‘3æ ¹Kçº¿çš„è¶‹åŠ¿
    recent_trend = (closes[-1] - closes[-3]) / closes[-3] * 100
    
    if recent_trend > 0.5:
        return f"å¼ºåŠ¿ä¸Šæ¶¨è¶‹åŠ¿ (+{recent_trend:.2f}%)"
    elif recent_trend > 0.1:
        return f"æ¸©å’Œä¸Šæ¶¨è¶‹åŠ¿ (+{recent_trend:.2f}%)"
    elif recent_trend < -0.5:
        return f"å¼ºåŠ¿ä¸‹è·Œè¶‹åŠ¿ ({recent_trend:.2f}%)"
    elif recent_trend < -0.1:
        return f"æ¸©å’Œä¸‹è·Œè¶‹åŠ¿ ({recent_trend:.2f}%)"
    else:
        return f"æ¨ªç›˜æ•´ç† ({recent_trend:.2f}%)"

def analyze_rsi(rsi: float):
    """åˆ†æRSIæŒ‡æ ‡"""
    if rsi > 70:
        return f"è¶…ä¹°åŒºåŸŸ ({rsi:.1f})ï¼Œå¯èƒ½å›è°ƒ"
    elif rsi > 60:
        return f"åå¼ºåŒºåŸŸ ({rsi:.1f})ï¼Œä¸Šæ¶¨åŠ¨èƒ½è¾ƒå¼º"
    elif rsi < 30:
        return f"è¶…å–åŒºåŸŸ ({rsi:.1f})ï¼Œå¯èƒ½åå¼¹"
    elif rsi < 40:
        return f"åå¼±åŒºåŸŸ ({rsi:.1f})ï¼Œä¸‹è·Œå‹åŠ›è¾ƒå¤§"
    else:
        return f"ä¸­æ€§åŒºåŸŸ ({rsi:.1f})ï¼Œæ— æ˜æ˜¾æ–¹å‘"

def analyze_bollinger_bands(bb_position: float):
    """åˆ†æå¸ƒæ—å¸¦ä½ç½®"""
    if bb_position > 0.8:
        return f"æ¥è¿‘ä¸Šè½¨ ({bb_position:.3f})ï¼Œå¯èƒ½é‡é˜»å›è½"
    elif bb_position > 0.6:
        return f"åä¸Šä½ç½® ({bb_position:.3f})ï¼Œä¸Šæ¶¨ç©ºé—´æœ‰é™"
    elif bb_position < 0.2:
        return f"æ¥è¿‘ä¸‹è½¨ ({bb_position:.3f})ï¼Œå¯èƒ½è·å¾—æ”¯æ’‘"
    elif bb_position < 0.4:
        return f"åä¸‹ä½ç½® ({bb_position:.3f})ï¼Œä¸‹è·Œç©ºé—´æœ‰é™"
    else:
        return f"ä¸­è½¨é™„è¿‘ ({bb_position:.3f})ï¼Œæ–¹å‘ä¸æ˜"

def analyze_volume(last_5: pd.DataFrame):
    """åˆ†ææˆäº¤é‡è¶‹åŠ¿"""
    volumes = last_5['volume'].values
    if len(volumes) < 3:
        return "æ•°æ®ä¸è¶³"
    
    recent_avg = volumes[-3:].mean()
    current_volume = volumes[-1]
    
    volume_ratio = current_volume / recent_avg
    
    if volume_ratio > 1.5:
        return f"æˆäº¤é‡æ”¾å¤§ ({volume_ratio:.2f}å€)ï¼Œå¸‚åœºæ´»è·ƒ"
    elif volume_ratio > 1.2:
        return f"æˆäº¤é‡å¢åŠ  ({volume_ratio:.2f}å€)ï¼Œäº¤æŠ•æ´»è·ƒ"
    elif volume_ratio < 0.7:
        return f"æˆäº¤é‡èç¼© ({volume_ratio:.2f}å€)ï¼Œå¸‚åœºè§‚æœ›"
    else:
        return f"æˆäº¤é‡æ­£å¸¸ ({volume_ratio:.2f}å€)ï¼Œäº¤æŠ•å¹³ç¨³"

def get_overall_analysis(change_ratio: float, direction: str, last_row: pd.Series):
    """ç»¼åˆåˆ¤æ–­"""
    abs_change = abs(change_ratio) * 100
    
    if abs_change > 3:
        intensity = "è¾ƒå¤§"
        confidence = "ä¸­ç­‰"
    elif abs_change > 1.5:
        intensity = "ä¸­ç­‰"
        confidence = "è¾ƒé«˜"
    elif abs_change > 0.5:
        intensity = "æ¸©å’Œ"
        confidence = "é«˜"
    else:
        intensity = "è½»å¾®"
        confidence = "å¾ˆé«˜"
    
    if direction == "æ¶¨":
        return f"åŸºäºæŠ€æœ¯æŒ‡æ ‡ç»¼åˆåˆ†æï¼Œé¢„è®¡å°†å‡ºç°{intensity}ä¸Šæ¶¨ï¼Œç½®ä¿¡åº¦{confidence}ï¼Œå»ºè®®å…³æ³¨æ”¯æ’‘ä½"
    else:
        return f"åŸºäºæŠ€æœ¯æŒ‡æ ‡ç»¼åˆåˆ†æï¼Œé¢„è®¡å°†å‡ºç°{intensity}ä¸‹è·Œï¼Œç½®ä¿¡åº¦{confidence}ï¼Œå»ºè®®å…³æ³¨é˜»åŠ›ä½"

def analyze_macd(macd_histogram: float):
    """åˆ†æMACDæŒ‡æ ‡"""
    if macd_histogram > 0:
        if macd_histogram > 100:
            return f"å¼ºåŠ¿ä¸Šæ¶¨ä¿¡å· ({macd_histogram:.2f})"
        else:
            return f"æ¸©å’Œä¸Šæ¶¨ä¿¡å· ({macd_histogram:.2f})"
    else:
        if macd_histogram < -100:
            return f"å¼ºåŠ¿ä¸‹è·Œä¿¡å· ({macd_histogram:.2f})"
        else:
            return f"æ¸©å’Œä¸‹è·Œä¿¡å· ({macd_histogram:.2f})"

def analyze_kdj(k: float, d: float, j: float):
    """åˆ†æKDJæŒ‡æ ‡"""
    if k > 80 and d > 80:
        return f"è¶…ä¹°åŒºåŸŸ (K:{k:.1f}, D:{d:.1f}, J:{j:.1f})ï¼Œå¯èƒ½å›è°ƒ"
    elif k < 20 and d < 20:
        return f"è¶…å–åŒºåŸŸ (K:{k:.1f}, D:{d:.1f}, J:{j:.1f})ï¼Œå¯èƒ½åå¼¹"
    elif k > d:
        return f"é‡‘å‰ä¿¡å· (K:{k:.1f}, D:{d:.1f}, J:{j:.1f})ï¼Œä¸Šæ¶¨æ¦‚ç‡è¾ƒå¤§"
    else:
        return f"æ­»å‰ä¿¡å· (K:{k:.1f}, D:{d:.1f}, J:{j:.1f})ï¼Œä¸‹è·Œæ¦‚ç‡è¾ƒå¤§"

def analyze_moving_averages(ma5_ratio: float, ma10_ratio: float, ma20_ratio: float):
    """åˆ†æç§»åŠ¨å¹³å‡çº¿"""
    if ma5_ratio > 1.01 and ma10_ratio > 1.01:
        return f"å¼ºåŠ¿ä¸Šæ¶¨ (MA5:{ma5_ratio:.3f}, MA10:{ma10_ratio:.3f}, MA20:{ma20_ratio:.3f})"
    elif ma5_ratio < 0.99 and ma10_ratio < 0.99:
        return f"å¼ºåŠ¿ä¸‹è·Œ (MA5:{ma5_ratio:.3f}, MA10:{ma10_ratio:.3f}, MA20:{ma20_ratio:.3f})"
    elif ma5_ratio > ma10_ratio > ma20_ratio:
        return f"å¤šå¤´æ’åˆ— (MA5:{ma5_ratio:.3f}, MA10:{ma10_ratio:.3f}, MA20:{ma20_ratio:.3f})"
    elif ma5_ratio < ma10_ratio < ma20_ratio:
        return f"ç©ºå¤´æ’åˆ— (MA5:{ma5_ratio:.3f}, MA10:{ma10_ratio:.3f}, MA20:{ma20_ratio:.3f})"
    else:
        return f"éœ‡è¡æ•´ç† (MA5:{ma5_ratio:.3f}, MA10:{ma10_ratio:.3f}, MA20:{ma20_ratio:.3f})"

def analyze_momentum(momentum_5: float, momentum_10: float):
    """åˆ†æåŠ¨é‡æŒ‡æ ‡"""
    if momentum_5 > 0.02 and momentum_10 > 0.02:
        return f"å¼ºåŠ¿ä¸Šæ¶¨åŠ¨é‡ (5æ—¥:{momentum_5*100:.2f}%, 10æ—¥:{momentum_10*100:.2f}%)"
    elif momentum_5 < -0.02 and momentum_10 < -0.02:
        return f"å¼ºåŠ¿ä¸‹è·ŒåŠ¨é‡ (5æ—¥:{momentum_5*100:.2f}%, 10æ—¥:{momentum_10*100:.2f}%)"
    elif momentum_5 > 0:
        return f"çŸ­æœŸä¸Šæ¶¨åŠ¨é‡ (5æ—¥:{momentum_5*100:.2f}%, 10æ—¥:{momentum_10*100:.2f}%)"
    else:
        return f"çŸ­æœŸä¸‹è·ŒåŠ¨é‡ (5æ—¥:{momentum_5*100:.2f}%, 10æ—¥:{momentum_10*100:.2f}%)"

if __name__ == "__main__":
    df = pd.read_csv(DATA_PATH)
    # é‡å‘½ååˆ—ä»¥åŒ¹é…é¢„å¤„ç†å‡½æ•°
    df = df.rename(columns={
        'closeTime': 'timestamp',
        'open': 'open',
        'high': 'high',
        'low': 'low',
        'close': 'close',
        'volume': 'volume'
    })
    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
    df = df.sort_values(by='timestamp').reset_index(drop=True)
    
    # æ‰“å°æœ€åä¸€æ ¹Kçº¿
    print("ã€æœ€åä¸€æ ¹Kçº¿ã€‘")
    print(df.iloc[-1][['timestamp', 'open', 'high', 'low', 'close', 'volume']])

    # é¢„æµ‹ä¸‹ä¸€æ ¹Kçº¿
    result = predict_next_candle_improved(df)
    if result:
        print("\nã€é¢„æµ‹çš„ä¸‹ä¸€æ ¹Kçº¿ã€‘")
        print(result)
        # å¦‚æœæ•°æ®é›†é‡Œæœ‰çœŸå®çš„ä¸‹ä¸€æ ¹Kçº¿ï¼Œä¹Ÿæ‰“å°å‡ºæ¥
        next_time = pd.to_datetime(result["é¢„æµ‹æ—¶é—´"])
        real_next = df[df['timestamp'] == next_time]
        if not real_next.empty:
            print("\nã€çœŸå®çš„ä¸‹ä¸€æ ¹Kçº¿ã€‘")
            print(real_next.iloc[0][['timestamp', 'open', 'high', 'low', 'close', 'volume']])
        else:
            print("\nã€çœŸå®çš„ä¸‹ä¸€æ ¹Kçº¿ã€‘")
            print("æ•°æ®é›†ä¸­æ²¡æœ‰ä¸‹ä¸€æ ¹Kçº¿ï¼ˆå¯èƒ½æ˜¯æœ€æ–°ä¸€æ ¹ï¼‰")
    else:
        print("é¢„æµ‹å¤±è´¥ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹") 