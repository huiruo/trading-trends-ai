# feature_analysis.py - ç‰¹å¾åˆ†æå·¥å…·
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from preprocess import load_and_preprocess, create_sequences
from technical_indicators import add_technical_indicators
from config_improved import FEATURE_COLUMNS, WINDOW_SIZE
import seaborn as sns

def analyze_features(df):
    """åˆ†æç‰¹å¾ï¼Œæ‰¾å‡ºå¯èƒ½å¯¼è‡´æç«¯é¢„æµ‹çš„ç‰¹å¾"""
    print("=== ç‰¹å¾åˆ†ææŠ¥å‘Š ===\n")
    
    # æ·»åŠ æŠ€æœ¯æŒ‡æ ‡
    df_with_indicators = add_technical_indicators(df)
    
    # è®¡ç®—æ¯æ ¹Kçº¿çš„æ¶¨è·Œå¹…
    df_with_indicators['change_ratio'] = df_with_indicators['close'].pct_change()
    
    print("1. ä»·æ ¼å˜åŒ–ç»Ÿè®¡:")
    print(f"   æœ€å¤§æ¶¨å¹…: {df_with_indicators['change_ratio'].max()*100:.2f}%")
    print(f"   æœ€å¤§è·Œå¹…: {df_with_indicators['change_ratio'].min()*100:.2f}%")
    print(f"   å¹³å‡æ¶¨è·Œå¹…: {df_with_indicators['change_ratio'].abs().mean()*100:.2f}%")
    print(f"   æ ‡å‡†å·®: {df_with_indicators['change_ratio'].std()*100:.2f}%\n")
    
    # åˆ†ææ¯ä¸ªç‰¹å¾çš„ç»Ÿè®¡ä¿¡æ¯
    print("2. ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯:")
    feature_stats = {}
    
    for feature in FEATURE_COLUMNS:
        if feature in df_with_indicators.columns:
            values = df_with_indicators[feature].dropna()
            feature_stats[feature] = {
                'mean': values.mean(),
                'std': values.std(),
                'min': values.min(),
                'max': values.max(),
                'range': values.max() - values.min(),
                'has_inf': np.isinf(values).any(),
                'has_nan': values.isna().any()
            }
            
            print(f"   {feature}:")
            print(f"     èŒƒå›´: [{values.min():.4f}, {values.max():.4f}]")
            print(f"     å‡å€¼: {values.mean():.4f}, æ ‡å‡†å·®: {values.std():.4f}")
            if np.isinf(values).any():
                print(f"     âš ï¸ åŒ…å«æ— ç©·å¤§å€¼")
            if values.isna().any():
                print(f"     âš ï¸ åŒ…å«NaNå€¼")
    
    # æ‰¾å‡ºå¼‚å¸¸ç‰¹å¾
    print("\n3. å¼‚å¸¸ç‰¹å¾æ£€æµ‹:")
    problematic_features = []
    
    for feature, stats in feature_stats.items():
        # æ£€æŸ¥æ˜¯å¦æœ‰æ— ç©·å¤§å€¼
        if stats['has_inf']:
            problematic_features.append((feature, "åŒ…å«æ— ç©·å¤§å€¼"))
            print(f"   âŒ {feature}: åŒ…å«æ— ç©·å¤§å€¼")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰NaNå€¼
        if stats['has_nan']:
            problematic_features.append((feature, "åŒ…å«NaNå€¼"))
            print(f"   âŒ {feature}: åŒ…å«NaNå€¼")
        
        # æ£€æŸ¥æ•°å€¼èŒƒå›´æ˜¯å¦å¼‚å¸¸
        if stats['range'] > 1000000:  # èŒƒå›´è¿‡å¤§
            problematic_features.append((feature, "æ•°å€¼èŒƒå›´è¿‡å¤§"))
            print(f"   âš ï¸ {feature}: æ•°å€¼èŒƒå›´è¿‡å¤§ ({stats['range']:.2f})")
        
        # æ£€æŸ¥æ ‡å‡†å·®æ˜¯å¦å¼‚å¸¸
        if stats['std'] > 10000:  # æ ‡å‡†å·®è¿‡å¤§
            problematic_features.append((feature, "æ ‡å‡†å·®è¿‡å¤§"))
            print(f"   âš ï¸ {feature}: æ ‡å‡†å·®è¿‡å¤§ ({stats['std']:.2f})")
    
    # ç‰¹å¾ä¸ä»·æ ¼å˜åŒ–çš„ç›¸å…³æ€§åˆ†æ
    print("\n4. ç‰¹å¾ä¸ä»·æ ¼å˜åŒ–çš„ç›¸å…³æ€§:")
    correlations = {}
    
    for feature in FEATURE_COLUMNS:
        if feature in df_with_indicators.columns:
            corr = df_with_indicators[feature].corr(df_with_indicators['change_ratio'])
            correlations[feature] = corr
            print(f"   {feature}: {corr:.4f}")
    
    # æ‰¾å‡ºç›¸å…³æ€§æœ€å¼ºçš„ç‰¹å¾
    sorted_correlations = sorted(correlations.items(), key=lambda x: abs(x[1]), reverse=True)
    print(f"\n   ç›¸å…³æ€§æœ€å¼ºçš„ç‰¹å¾: {sorted_correlations[0][0]} ({sorted_correlations[0][1]:.4f})")
    print(f"   ç›¸å…³æ€§æœ€å¼±çš„ç‰¹å¾: {sorted_correlations[-1][0]} ({sorted_correlations[-1][1]:.4f})")
    
    return feature_stats, correlations, problematic_features

def suggest_feature_fixes(problematic_features, correlations):
    """æ ¹æ®åˆ†æç»“æœå»ºè®®ç‰¹å¾ä¿®å¤æ–¹æ¡ˆ"""
    print("\n=== ç‰¹å¾ä¿®å¤å»ºè®® ===\n")
    
    if not problematic_features:
        print("âœ… æ²¡æœ‰å‘ç°æ˜æ˜¾çš„é—®é¢˜ç‰¹å¾")
    else:
        print("å»ºè®®ä¿®å¤ä»¥ä¸‹ç‰¹å¾:")
        for feature, issue in problematic_features:
            print(f"   - {feature}: {issue}")
    
    print("\nå»ºè®®ä¿ç•™çš„ç‰¹å¾ (æŒ‰ç›¸å…³æ€§æ’åº):")
    sorted_correlations = sorted(correlations.items(), key=lambda x: abs(x[1]), reverse=True)
    for i, (feature, corr) in enumerate(sorted_correlations[:10]):  # åªæ˜¾ç¤ºå‰10ä¸ª
        print(f"   {i+1}. {feature}: {corr:.4f}")

def create_feature_visualization(df):
    """åˆ›å»ºç‰¹å¾å¯è§†åŒ–å›¾è¡¨"""
    df_with_indicators = add_technical_indicators(df)
    df_with_indicators['change_ratio'] = df_with_indicators['close'].pct_change()
    
    # åˆ›å»ºå­å›¾
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # 1. ä»·æ ¼å˜åŒ–åˆ†å¸ƒ
    axes[0, 0].hist(df_with_indicators['change_ratio'].dropna() * 100, bins=50, alpha=0.7)
    axes[0, 0].set_title('ä»·æ ¼å˜åŒ–åˆ†å¸ƒ')
    axes[0, 0].set_xlabel('æ¶¨è·Œå¹… (%)')
    axes[0, 0].set_ylabel('é¢‘æ¬¡')
    
    # 2. ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾
    feature_cols = [col for col in FEATURE_COLUMNS if col in df_with_indicators.columns]
    corr_matrix = df_with_indicators[feature_cols + ['change_ratio']].corr()
    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[0, 1])
    axes[0, 1].set_title('ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾')
    
    # 3. ä¸»è¦ç‰¹å¾çš„æ—¶é—´åºåˆ—
    if 'rsi_14' in df_with_indicators.columns:
        axes[1, 0].plot(df_with_indicators['rsi_14'])
        axes[1, 0].set_title('RSIæ—¶é—´åºåˆ—')
        axes[1, 0].set_ylabel('RSI')
    
    # 4. ä»·æ ¼ä¸é¢„æµ‹ç›®æ ‡
    axes[1, 1].plot(df_with_indicators['close'])
    axes[1, 1].set_title('æ”¶ç›˜ä»·æ—¶é—´åºåˆ—')
    axes[1, 1].set_ylabel('ä»·æ ¼')
    
    plt.tight_layout()
    plt.savefig('feature_analysis.png', dpi=300, bbox_inches='tight')
    print("\nğŸ“Š ç‰¹å¾åˆ†æå›¾è¡¨å·²ä¿å­˜ä¸º 'feature_analysis.png'")

if __name__ == "__main__":
    # åŠ è½½æ•°æ®
    df = pd.read_csv("dataset/btc_1h.csv")
    df = df.rename(columns={
        'closeTime': 'timestamp',
        'open': 'open',
        'high': 'high',
        'low': 'low',
        'close': 'close',
        'volume': 'volume'
    })
    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
    df = df.sort_values(by='timestamp').reset_index(drop=True)
    
    # åˆ†æç‰¹å¾
    feature_stats, correlations, problematic_features = analyze_features(df)
    
    # å»ºè®®ä¿®å¤æ–¹æ¡ˆ
    suggest_feature_fixes(problematic_features, correlations)
    
    # åˆ›å»ºå¯è§†åŒ–
    create_feature_visualization(df) 